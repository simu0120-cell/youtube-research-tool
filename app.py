import streamlit as st
import pandas as pd
import datetime
from googleapiclient.discovery import build

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ëŒ€í‘œë‹˜ ì „ìš© ìœ íŠœë¸Œ ë¶„ì„ê¸°", layout="wide")

API_KEY = st.secrets["YOUTUBE_API_KEY"]  # ğŸ”‘ streamlit secretsì— ì €ì¥ í•„ìš”
client = build("youtube", "v3", developerKey=API_KEY)

# =========================
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# =========================
def pick_order(order_label: str) -> str:
    if "ì¡°íšŒìˆ˜" in order_label:
        return "viewCount"
    elif "ìµœê·¼" in order_label:
        return "date"
    else:
        return "relevance"

def pick_duration(label: str) -> str:
    if label == "4ë¶„ ë¯¸ë§Œ":
        return "short"
    elif label == "4~20ë¶„":
        return "medium"
    elif label == "20ë¶„ ì´ìƒ":
        return "long"
    return "any"

def expand_queries(q: str) -> list[str]:
    """ê°„ë‹¨í•œ ë‹¤ë³€í˜• ì¿¼ë¦¬ ìƒì„±: ë”°ì˜´í‘œ, ê³µë°±ì œê±°, ì—°ê´€ ë‹¨ì–´ ì¡°í•©."""
    q = q.strip()
    variants = [
        q,
        f"\"{q}\"",
        q.replace(" ", ""),
    ]
    tails = ["ì¶”ì²œ","ê¿€í…œ","ë¦¬ë·°","í›„ê¸°","TOP","Best","ëª¨ìŒ","ê°€ì„±ë¹„","ì‡¼ì¸ "]
    for t in tails:
        variants.append(f"{q} {t}")
    seen, uniq = set(), []
    for v in variants:
        if v not in seen:
            seen.add(v); uniq.append(v)
    return uniq

def search_video_ids(client, q, max_results, order, published_after=None, video_duration="any", published_before=None):
    ids = []
    req = client.search().list(
        q=q,
        part="id",
        type="video",
        order=order,
        maxResults=min(50, max_results),
        publishedAfter=published_after,
        publishedBefore=published_before,
        videoDuration=video_duration
    )
    res = req.execute()
    for item in res.get("items", []):
        ids.append(item["id"]["videoId"])
    return ids

def fetch_videos_and_channels(client, ids):
    # ë¹„ë””ì˜¤ ë©”íƒ€ ìˆ˜ì§‘
    df_list = []
    ch_map = {}
    for i in range(0, len(ids), 50):
        batch = ids[i:i+50]
        res = client.videos().list(
            part="snippet,statistics,contentDetails",
            id=",".join(batch)
        ).execute()
        for item in res.get("items", []):
            vid = item["id"]
            snippet = item["snippet"]
            stats = item.get("statistics", {})
            df_list.append({
                "video_id": vid,
                "channel_id": snippet["channelId"],
                "channel_title": snippet["channelTitle"],
                "title": snippet["title"],
                "published_at": snippet["publishedAt"],
                "thumbnail_url": snippet["thumbnails"]["default"]["url"],
                "view_count": int(stats.get("viewCount", 0)),
                "like_count": int(stats.get("likeCount", 0)),
                "comment_count": int(stats.get("commentCount", 0)),
                "duration": item["contentDetails"]["duration"],
            })
    df = pd.DataFrame(df_list)
    return df, ch_map

def enrich_dataframe(df, ch_map):
    if df.empty:
        return df
    df["published_at_dt"] = pd.to_datetime(df["published_at"])
    df["duration_mmss"] = df["duration"].astype(str)
    df["like_rate_pct"] = df["like_count"] / df["view_count"].replace(0,1) * 100
    df["comment_per_mille"] = df["comment_count"] / df["view_count"].replace(0,1) * 1000
    df["CII"] = (
        df["like_rate_pct"].fillna(0) * 0.7 +
        df["comment_per_mille"].fillna(0) * 0.3
    )
    df["channel_share_pct"] = 100 / df.groupby("channel_title")["channel_title"].transform("count")
    return df

# =========================
# ì‚¬ì´ë“œë°”
# =========================
with st.sidebar:
    st.subheader("ê²€ìƒ‰ ì¡°ê±´")
    keyword = st.text_input("í‚¤ì›Œë“œ", value="ì¿ íŒ¡ ê¿€í…œ")

    uploaded_when = st.selectbox(
        "ì—…ë¡œë“œ ì‹œê¸°",
        ["ì˜¬í•´", "ì´ë²ˆë‹¬", "ì´ë²ˆì£¼", "ìµœê·¼ 7ì¼", "ì˜¤ëŠ˜", "ì œí•œ ì—†ìŒ"],
        index=1
    )

    duration_label = st.selectbox("ì˜ìƒ ê¸¸ì´", ["ì „ì²´","4ë¶„ ë¯¸ë§Œ","4~20ë¶„","20ë¶„ ì´ìƒ"], index=1)
    order = st.selectbox("ì •ë ¬", ["ì¡°íšŒìˆ˜(ë‚´ë¦¼ì°¨ìˆœ)", "ìµœê·¼ ì—…ë¡œë“œ", "CII(ë‚´ë¦¼ì°¨ìˆœ)"], 0)

    expand_mode = st.checkbox("í™•ì¥ ê²€ìƒ‰(ë‹¤ë³€í˜•)", value=True, help="ë”°ì˜´í‘œ/ê³µë°±ì œê±°/ì—°ê´€ë‹¨ì–´ ì¡°í•©ìœ¼ë¡œ ë” ë§ì€ ì†ŒìŠ¤ ìˆ˜ì§‘")

    max_results = st.slider("ìµœëŒ€ ê²°ê³¼ ìˆ˜", 10, 300, 80, 10)

    sample_take = st.number_input("í•œ ë²ˆì— ì„ íƒí•  ê°œìˆ˜", 1, 50, 5, 1)
    run = st.button("ê²€ìƒ‰ ì‹¤í–‰", type="primary")

# =========================
# ì—…ë¡œë“œ ì‹œê¸° í•„í„° ê³„ì‚°
# =========================
published_after, published_before = None, None
today = datetime.datetime.utcnow()

if uploaded_when != "ì œí•œ ì—†ìŒ":
    if uploaded_when == "ì˜¤ëŠ˜":
        published_after = (today - datetime.timedelta(days=1)).isoformat("T")+"Z"
    elif uploaded_when == "ìµœê·¼ 7ì¼":
        published_after = (today - datetime.timedelta(days=7)).isoformat("T")+"Z"
    elif uploaded_when == "ì´ë²ˆì£¼":
        published_after = (today - datetime.timedelta(days=7)).isoformat("T")+"Z"
    elif uploaded_when == "ì´ë²ˆë‹¬":
        published_after = (today - datetime.timedelta(days=30)).isoformat("T")+"Z"
    elif uploaded_when == "ì˜¬í•´":
        published_after = (today - datetime.timedelta(days=365)).isoformat("T")+"Z"

# =========================
# ë©”ì¸ ì‹¤í–‰
# =========================
if run:
    with st.spinner("ê²€ìƒ‰ ì¤‘..."):
        if expand_mode:
            queries = expand_queries(keyword)
            want = max_results
            ids_set: set[str] = set()
            per = max(10, want // max(1, len(queries)))
            for qv in queries:
                if len(ids_set) >= want:
                    break
                got = search_video_ids(
                    client=client,
                    q=qv,
                    max_results=min(per, want - len(ids_set)),
                    order=pick_order(order),
                    published_after=published_after,
                    video_duration=pick_duration(duration_label),
                    published_before=published_before
                )
                ids_set.update(got)
            ids = list(ids_set)[:want]
        else:
            ids = search_video_ids(
                client=client,
                q=keyword,
                max_results=max_results,
                order=pick_order(order),
                published_after=published_after,
                video_duration=pick_duration(duration_label),
                published_before=published_before
            )

        if not ids:
            st.error("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤/ì¿¼í„°/í•„í„° í™•ì¸ í•„ìš”")
            st.stop()

        df_raw, ch_map = fetch_videos_and_channels(client, ids)
        df = enrich_dataframe(df_raw, ch_map)

        # í‘œ ì¤€ë¹„
        show_cols = [
            "video_id","channel_title","title","published_at_dt",
            "view_count","like_count","comment_count",
            "like_rate_pct","comment_per_mille","duration_mmss",
            "CII","channel_share_pct","thumbnail_url"
        ]
        nice_df = df[show_cols].copy()
        nice_df["ì˜ìƒ ë§í¬"] = "https://www.youtube.com/watch?v=" + nice_df["video_id"]
        nice_df["ì¸ë„¤ì¼"] = nice_df["thumbnail_url"]

        nice_df = nice_df.rename(columns={
            "video_id":"ì˜ìƒID",
            "channel_title":"ì±„ë„ëª…",
            "title":"ì œëª©",
            "published_at_dt":"ê²Œì‹œì¼",
            "view_count":"ì¡°íšŒìˆ˜",
            "like_count":"ì¢‹ì•„ìš”ìˆ˜",
            "comment_count":"ëŒ“ê¸€ìˆ˜",
            "like_rate_pct":"ì¢‹ì•„ìš”/ì¡°íšŒìˆ˜(%)",
            "comment_per_mille":"ëŒ“ê¸€/ì¡°íšŒìˆ˜(â€°)",
            "duration_mmss":"ì˜ìƒ ê¸¸ì´",
            "CII":"CII",
            "channel_share_pct":"ì±„ë„ ì ìœ ìœ¨(%)",
        })

        display_cols = [
            "ì¸ë„¤ì¼", "ì˜ìƒ ë§í¬",
            "ì˜ìƒID","ì±„ë„ëª…","ì œëª©","ê²Œì‹œì¼",
            "ì¡°íšŒìˆ˜","ì¢‹ì•„ìš”ìˆ˜","ëŒ“ê¸€ìˆ˜",
            "ì¢‹ì•„ìš”/ì¡°íšŒìˆ˜(%)","ëŒ“ê¸€/ì¡°íšŒìˆ˜(â€°)","ì˜ìƒ ê¸¸ì´","CII","ì±„ë„ ì ìœ ìœ¨(%)"
        ]

        st.dataframe(
            nice_df[display_cols],
            use_container_width=True,
            hide_index=True,
            column_config={
                "ì¸ë„¤ì¼": st.column_config.ImageColumn("ì¸ë„¤ì¼", width="small"),
                "ì˜ìƒ ë§í¬": st.column_config.LinkColumn("ì˜ìƒ ë³´ê¸°", display_text="ì—´ê¸°"),
            },
        )

        csv = nice_df[display_cols].to_csv(index=False).encode("utf-8-sig")
        st.download_button("í˜„ì¬ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="youtube_results.csv")

        st.markdown("---")
        st.subheader("ì˜ìƒ ë¯¸ë¦¬ë³´ê¸°")
        sel_options = (nice_df["ì œëª©"] + " | " + nice_df["ì±„ë„ëª…"] + " | " + nice_df["ì˜ìƒID"]).tolist()
        sel = st.selectbox("ë¯¸ë¦¬ë³¼ ì˜ìƒ ì„ íƒ", options=["ì„ íƒ ì•ˆ í•¨"] + sel_options, index=0)
        if sel != "ì„ íƒ ì•ˆ í•¨":
            vid = sel.split("|")[-1].strip()
            st.video(f"https://www.youtube.com/watch?v={vid}")
